{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VCNXxZB6eaS0"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ChainMDP(gym.Env):\n",
        "    \"\"\"Chain MDP\n",
        "    The environment consists of a chain of N states and the agent always starts in state s2,\n",
        "    from where it can either move left or right.\n",
        "    In state s1, the agent receives a small reward of r = 0.001 by moving left.\n",
        "    A larger reward r = 1 is recived when moving right from state sN.\n",
        "    This environment is described in\n",
        "    Deep Exploration via Bootstrapped DQN(https://papers.nips.cc/paper/6501-deep-exploration-via-bootstrapped-dqn.pdf)\n",
        "    \"\"\"\n",
        "    def __init__(self, n):\n",
        "        self.n = n\n",
        "        self.state = 1  # start at s2\n",
        "        self.action_space = spaces.Discrete(2) # left or right\n",
        "        self.observation_space = spaces.Discrete(self.n) # 0 ~ n-1 index의 observations_space 존재\n",
        "        self.max_nsteps = n + 8 #?\n",
        "\n",
        "    def step(self, action):\n",
        "        assert self.action_space.contains(action)\n",
        "        v = np.arange(self.n) #[0,1,2, ... , n-1]\n",
        "        reward = lambda s, a: 1.0 if (s == (self.n - 1) and a == 1) else (0.001 if (s == 0 and a == 0) else 0) # a == 1 : right\n",
        "        is_done = lambda nsteps: nsteps >= self.max_nsteps\n",
        "\n",
        "        r = reward(self.state, action)\n",
        "        if action:    # right\n",
        "            if self.state != self.n - 1:\n",
        "                self.state += 1\n",
        "        else:   # left\n",
        "            if self.state != 0:\n",
        "                self.state -= 1\n",
        "        self.nsteps += 1\n",
        "\n",
        "        return (v <= self.state).astype('float32'), r, is_done(self.nsteps),  None\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        v = np.arange(self.n)\n",
        "        self.state = 1\n",
        "        self.nsteps = 0\n",
        "        return (v <= self.state).astype('float32') # reset시 1번 state로, nsteps 바꾸고"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from collections import deque\n",
        "\n",
        "# define neural net Q_\\theta(s,a) as a class\n",
        "\n",
        "class Qfunction(keras.Model):\n",
        "    \n",
        "    def __init__(self, nState, nAction, hidden_dims):\n",
        "        \"\"\"\n",
        "        nState: dimension of state space\n",
        "        nAction: dimension of action space\n",
        "        hidden_dims: list containing output dimension of hidden layers \n",
        "        \"\"\"\n",
        "        super(Qfunction, self).__init__()\n",
        "\n",
        "        # Layer weight initializer\n",
        "        initializer = keras.initializers.RandomUniform(minval=-1., maxval=1.)\n",
        "\n",
        "        # Input Layer\n",
        "        self.input_layer = keras.layers.InputLayer(input_shape=(nState,))\n",
        "        \n",
        "        # Hidden Layer\n",
        "        self.hidden_layers = []\n",
        "        for hidden_dim in hidden_dims:\n",
        "            layer = keras.layers.Dense(hidden_dim, activation='relu',\n",
        "                                      kernel_initializer=initializer)\n",
        "            self.hidden_layers.append(layer) \n",
        "        self.output_layer = keras.layers.Dense(nAction, activation='linear', kernel_initializer=initializer) \n",
        "    \n",
        "    @tf.function\n",
        "    def call(self, states):\n",
        "        x = self.input_layer(states)\n",
        "        for hidden_layer in self.hidden_layers:\n",
        "            x = hidden_layer(x)\n",
        "        return self.output_layer(x)\n",
        "\n",
        "# Wrapper class for training Qfunction and updating weights (target network) \n",
        "\n",
        "class DQN(object):\n",
        "    \n",
        "    def __init__(self, nState, nAction, hidden_dims, learning_rate):\n",
        "        \"\"\"\n",
        "        nState: dimension of state space\n",
        "        nAction: dimension of action space\n",
        "        optimizer: \n",
        "        \"\"\"\n",
        "        self.qfunction = Qfunction(nState, nAction, hidden_dims)\n",
        "        self.optimizer = keras.optimizers.Adam(learning_rate)\n",
        "        self.nState = nState\n",
        "        self.nAction = nAction\n",
        "\n",
        "    def _predict_q(self, states, actions):\n",
        "        \"\"\"\n",
        "        states represent s_t\n",
        "        actions represent a_t\n",
        "        \"\"\"\n",
        "        #print(states, actions)\n",
        "        q_ = self.compute_Qvalues(states)\n",
        "        #print(q_)\n",
        "        one_hot_action = tf.one_hot(actions, 2)\n",
        "        #print(one_hot_action)\n",
        "        predicts = tf.reduce_sum(one_hot_action * q_, axis=1)\n",
        "        return predicts\n",
        "        \n",
        "\n",
        "    def _loss(self, Qpreds, targets):\n",
        "        \"\"\"\n",
        "        Qpreds represent Q_\\theta(s,a)\n",
        "        targets represent the terms E[r+gamma Q] in Bellman equations\n",
        "\n",
        "        This function is OBJECTIVE function\n",
        "        \"\"\"\n",
        "        return tf.math.reduce_mean(tf.square(Qpreds - targets))\n",
        "\n",
        "    \n",
        "    def compute_Qvalues(self, states):\n",
        "        \"\"\"\n",
        "        states: numpy array as input to the neural net, states should have\n",
        "        size [numsamples, nState], where numsamples is the number of samples\n",
        "        output: Q values for these states. The output should have size \n",
        "        [numsamples, nAction] as numpy array\n",
        "        \"\"\"\n",
        "        inputs = np.atleast_2d(states.astype('float32'))\n",
        "        return self.qfunction(inputs)\n",
        "\n",
        "\n",
        "    def train(self, states, actions, targets):\n",
        "        \"\"\"\n",
        "        states: numpy array as input to compute loss (s)\n",
        "        actions: numpy array as input to compute loss (a)\n",
        "        targets: numpy array as input to compute loss (Q targets)\n",
        "        \"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            Qpreds = self._predict_q(states, actions)\n",
        "            loss = self._loss(Qpreds, targets)\n",
        "        variables = self.qfunction.trainable_variables\n",
        "        gradients = tape.gradient(loss, variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "        return loss\n",
        "\n",
        "    def update_weights(self, from_network):\n",
        "        \"\"\"\n",
        "        We need a subroutine to update target network \n",
        "        i.e. to copy from principal network to target network. \n",
        "        This function is for copying  𝜃←𝜃target \n",
        "        \"\"\"\n",
        "        \n",
        "        from_var = from_network.qfunction.trainable_variables\n",
        "        to_var = self.qfunction.trainable_variables\n",
        "        \n",
        "        for v1, v2 in zip(from_var, to_var):\n",
        "            v2.assign(v1)\n",
        "\n",
        "\n",
        "class ReplayBuffer(object):\n",
        "    \n",
        "    def __init__(self, maxlength, n_ensemble, bernoulli_prob):\n",
        "        self.buffer = deque()\n",
        "        self.n_ensemble = n_ensemble\n",
        "        self.bernoulli_prob = bernoulli_prob\n",
        "        self.number = 0\n",
        "        self.maxlength = maxlength\n",
        "    \n",
        "    def push(self, state, action, next_state, reward, done):\n",
        "        mask = np.random.binomial(1, self.bernoulli_prob, self.n_ensemble)\n",
        "        self.buffer.append([state, action, next_state, reward, done, mask])\n",
        "        self.number += 1\n",
        "        if(self.number > self.maxlength):\n",
        "            self.pop()\n",
        "        \n",
        "    def pop(self):\n",
        "        while self.number > self.maxlength:\n",
        "            self.buffer.popleft()\n",
        "            self.number -= 1\n",
        "    \n",
        "    def sample(self, batchsize):\n",
        "        inds = np.random.choice(len(self.buffer), batchsize, replace=False)\n",
        "        return [self.buffer[idx] for idx in inds]\n",
        "\n",
        "\n",
        "class agent():\n",
        "    \n",
        "    def __init__(self, nState, nAction):\n",
        "        self.nState = nState\n",
        "        self.nAction = nAction\n",
        "        self.hidden_dims = [10, 5]\n",
        "        self.learning_rate = 0.3\n",
        "        self.targetQ_list = [DQN(self.nState, self.nAction, self.hidden_dims, self.learning_rate) for _ in range(10)]\n",
        "        self.principalQ_list = [DQN(self.nState, self.nAction, self.hidden_dims, self.learning_rate) for _ in range(10)]\n",
        "        self.buffer = ReplayBuffer(10000, 10, 0.9)\n",
        "        self.total_step = 0\n",
        "\n",
        "    def action(self, state):\n",
        "        vote_list = []\n",
        "        for Qprincipal in self.principalQ_list:\n",
        "            Q = Qprincipal.compute_Qvalues(state)\n",
        "            action = np.argmax(Q)\n",
        "            vote_list.append(action)\n",
        "      \n",
        "        return 1 if np.array(vote_list).sum() >= 5 else 0\n",
        "        \n",
        "    def observe(self, state, action, next_state, reward, done):\n",
        "        self.buffer.push(state, action, next_state, reward, done)\n",
        "    \n",
        "    def update_after_step(self):\n",
        "        if self.buffer.number < 20:\n",
        "            return\n",
        "        samples = self.buffer.sample(5)\n",
        "\n",
        "        experiences = [[[],[],[]] for _ in range(10)]\n",
        "        for sample in samples:\n",
        "            mask = sample[-1]\n",
        "\n",
        "            for index, item in enumerate(mask):\n",
        "                if item == 1:\n",
        "                    s = sample[0]\n",
        "                    a = sample[1]\n",
        "                    if sample[4]:\n",
        "                        d = sample[3]\n",
        "                    else:\n",
        "                        d = sample[3] + 0.99 * np.max(self.targetQ_list[index].compute_Qvalues(sample[2]))\n",
        "                    \n",
        "                    experiences[index][0].append(s)\n",
        "                    experiences[index][1].append(a)\n",
        "                    experiences[index][2].append(d)\n",
        "\n",
        "        for index, Qprincipal in enumerate(self.principalQ_list):\n",
        "            Qprincipal.train(np.array(experiences[index][0]),np.array(experiences[index][1]), np.array(experiences[index][2]))\n",
        "\n",
        "        self.total_step += 1\n",
        "\n",
        "        if self.total_step % 100 == 0 :\n",
        "            for i in range(10):\n",
        "                self.targetQ_list[i].update_weights(self.principalQ_list[i])"
      ],
      "metadata": {
        "id": "SVHZscUne4_z"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del agent"
      ],
      "metadata": {
        "id": "HFZZmQ5Sfwnx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "env = ChainMDP(10)\n",
        "s = env.reset()\n",
        "\n",
        "agent1 = agent(10, 2)\n",
        "\n",
        "def training(k):\n",
        "   for episode in range(k):\n",
        "       s = env.reset()\n",
        "       done = False\n",
        "\n",
        "       cum_reward = 0\n",
        "       while not done:\n",
        "            action = agent1.action(s)\n",
        "            ns, reward, done, _ = env.step(action)\n",
        "            cum_reward += reward\n",
        "            \n",
        "            #####################\n",
        "            # If your agent needs to update the weights at every time step, complete your update process in this area.\n",
        "            agent1.observe(s, action, ns, reward, done)\n",
        "            print(s, action, ns, reward, done)\n",
        "            agent1.update_after_step()\n",
        "\n",
        "            #####################\n",
        "            s = ns\n",
        "       print(episode, cum_reward)\n",
        "#training for 1000 episodes\n",
        "training(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nu3be26-fD-B",
        "outputId": "01b98039-fb1e-46b6-cfcd-d6945d342fcb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "0 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "1 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "2 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "3 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "4 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "5 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "6 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "7 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "8 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "9 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "10 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "11 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "12 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "13 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "14 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "15 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "16 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "17 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "18 10.0\n",
            "[1. 1. 0. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 0. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 0. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 0. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 0. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 0. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 0. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 0.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 False\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.] 1.0 True\n",
            "19 10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.action(env.reset())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLeFfbQcfUcY",
        "outputId": "3e37c194-8341-45ce-9a42-a18513f02b78"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}